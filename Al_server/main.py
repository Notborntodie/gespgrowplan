import pdfplumber
from fastapi import FastAPI, File, UploadFile, Request, Form
from fastapi.responses import JSONResponse, HTMLResponse, StreamingResponse
from fastapi.templating import Jinja2Templates
from fastapi.middleware.cors import CORSMiddleware
import os
import json
from llm_processor import LLMProcessor
from explanation_processor import ExplanationProcessor
from llm_stream_processor import LLMStreamProcessor

# Initialize FastAPI and templates
app = FastAPI()

# æ·»åŠ CORSä¸­é—´ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # åœ¨ç”Ÿäº§ç¯å¢ƒä¸­åº”è¯¥æŒ‡å®šå…·ä½“çš„åŸŸå
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

templates = Jinja2Templates(directory="templates")

# Initialize LLM processor with increased token limit
llm_processor = LLMProcessor(max_tokens=8000)

# Initialize explanation processor for fast explanation generation
explanation_processor = ExplanationProcessor(max_tokens=400)


# Initialize LLM stream processor for true streaming LLM output
llm_stream_processor = LLMStreamProcessor(max_tokens=16000)

# è¿›åº¦å­˜å‚¨
progress_storage = {}

def extract_pdf_text(file_path: str) -> str:
    """
    Extracts text content from PDF file using pdfplumber for better code formatting.
    
    Args:
        file_path (str): Path to the PDF file
        
    Returns:
        str: Extracted text content
    """
    try:
        pdf_text = ""
        with pdfplumber.open(file_path) as pdf:
            for page in pdf.pages:
                page_text = page.extract_text()
                if page_text:
                    pdf_text += page_text + "\n"
        return pdf_text.strip()
    except Exception as e:
        raise ValueError(f"Error extracting PDF text: {str(e)}")

async def process_pdf_file(file: UploadFile, use_llm: bool = True, parallel_workers: int = 3, progress_id: str = None, expected_questions: int = None):
    """
    å¤„ç†PDFæ–‡ä»¶
    
    Args:
        file: ä¸Šä¼ çš„æ–‡ä»¶
        use_llm: æ˜¯å¦ä½¿ç”¨å¤§æ¨¡å‹å¤„ç†
        parallel_workers: å¹¶è¡Œçº¿ç¨‹æ•°
        progress_id: è¿›åº¦ID
        expected_questions: é¢„æœŸé¢˜ç›®æ•°é‡ï¼ˆç”¨äºæ ¡å‡†ï¼‰
    """
    try:
        # æ‰“å°æ¥æ”¶åˆ°çš„å‚æ•°
        print(f"ğŸ”§ æ¥æ”¶åˆ°çš„å‚æ•°:")
        print(f"   - use_llm: {use_llm}")
        print(f"   - parallel_workers: {parallel_workers}")
        print(f"   - expected_questions: {expected_questions}")
        
        # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶
        file_path = f"temp_{file.filename}"
        with open(file_path, "wb") as buffer:
            content = await file.read()
            buffer.write(content)
        
        try:
            # æå–PDFæ–‡æœ¬
            pdf_text = extract_pdf_text(file_path)
            
            if not use_llm:
                # ä»…è¿”å›åŸå§‹æ–‡æœ¬
                return {
                    "filename": file.filename,
                    "raw_content": pdf_text,
                    "questions": [],
                    "status": "success",
                    "processed": False,
                    "question_count": 0
                }
            
            print(f"ğŸ“„ å¼€å§‹å¤„ç†PDFæ–‡ä»¶: {file.filename}")
            print(f"ğŸ“Š PDFæ–‡æœ¬é•¿åº¦: {len(pdf_text)} å­—ç¬¦")
            
            # å‘é€å¼€å§‹å¤„ç†çš„æ¶ˆæ¯
            if progress_id:
                progress_storage[progress_id] = {
                    "type": "start",
                    "message": f"å¼€å§‹å¤„ç†PDFæ–‡ä»¶: {file.filename}",
                    "text_length": len(pdf_text)
                }
            
            questions = llm_processor.process_pdf_text_with_progress(
                pdf_text, 
                max_workers=parallel_workers, 
                progress_id=progress_id,
                expected_questions=expected_questions
            )
            
            print(f"âœ… å¤„ç†å®Œæˆï¼Œæå–åˆ° {len(questions)} ä¸ªé¢˜ç›®")
            
            # å‘é€å®Œæˆæ¶ˆæ¯
            if progress_id:
                progress_storage[progress_id] = {
                    "type": "complete",
                    "message": f"å¤„ç†å®Œæˆï¼æ€»å…±æå–åˆ° {len(questions)} ä¸ªé¢˜ç›®",
                    "question_count": len(questions)
                }
            
            return {
                "filename": file.filename,
                "raw_content": pdf_text,
                "questions": questions,
                "status": "success",
                "processed": True,
                "question_count": len(questions),
                "segment_count": len(llm_processor.get_last_segments()) if hasattr(llm_processor, 'get_last_segments') else 1,
                "parallel_workers": parallel_workers,
                "expected_questions": expected_questions
            }
            
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if os.path.exists(file_path):
                os.remove(file_path)
                
    except Exception as e:
        return {
            "filename": file.filename,
            "error": str(e),
            "status": "error"
        }



@app.get("/", response_class=HTMLResponse)
async def home():
    """
    Renders the upload page with a form to upload a PDF.
    """
    return templates.TemplateResponse("upload.html", {"request": {}})

@app.post("/upload")
async def upload_file(
    file: UploadFile = File(...),
    use_llm: bool = Form(True),
    parallel_workers: int = Form(3),
    expected_questions: str = Form("")
):
    """
    ä¸Šä¼ PDFæ–‡ä»¶å¹¶å¤„ç†
    
    Args:
        file: ä¸Šä¼ çš„PDFæ–‡ä»¶
        use_llm: æ˜¯å¦ä½¿ç”¨å¤§æ¨¡å‹å¤„ç†
        parallel_workers: å¹¶è¡Œçº¿ç¨‹æ•°
        expected_questions: é¢„æœŸé¢˜ç›®æ•°é‡ï¼ˆç”¨äºæ ¡å‡†ï¼‰
    """
    # å¤„ç†expected_questionså‚æ•°
    expected_questions_int = None
    if expected_questions and expected_questions.strip():
        try:
            expected_questions_int = int(expected_questions)
        except ValueError:
            print(f"âš ï¸ é¢„æœŸé¢˜ç›®æ•°è½¬æ¢å¤±è´¥: {expected_questions}")
    
    return await process_pdf_file(file, use_llm, parallel_workers, expected_questions=expected_questions_int)

@app.get("/progress/{progress_id}")
async def get_progress(progress_id: str):
    """
    è·å–å¤„ç†è¿›åº¦
    """
    if progress_id in progress_storage:
        return progress_storage[progress_id]
    else:
        return {"type": "error", "message": "è¿›åº¦IDä¸å­˜åœ¨"}



@app.post("/api/extract")
async def extract_pdf_api(
    file: UploadFile = File(...), 
    use_llm: bool = Form(True), 
    parallel_workers: int = Form(3)
):
    """
    API endpoint for PDF extraction without web interface.
    Designed for programmatic usage.
    """
    return await process_pdf_file(file, use_llm, parallel_workers)

@app.post("/api/extract-raw")
async def extract_pdf_raw(file: UploadFile = File(...)):
    """
    Extract raw text only, without LLM processing.
    """
    return await process_pdf_file(file, use_llm=False)

@app.post("/api/generate-explanation")
async def generate_explanation(request: Request):
    """
    ä¸ºå•ä¸ªé¢˜ç›®ç”Ÿæˆè¯¦ç»†çš„ç­”æ¡ˆè§£æ
    
    è¯·æ±‚ä½“æ ¼å¼ï¼š
    {
        "question": {
            "question_text": "é¢˜ç›®æ–‡æœ¬",
            "question_type": "codeæˆ–text",
            "question_code": "ä»£ç å†…å®¹æˆ–ç©ºå­—ç¬¦ä¸²",
            "correct_answer": "æ­£ç¡®ç­”æ¡ˆæ ‡ç­¾",
            "explanation": "åŸå§‹è§£é‡Šè¯´æ˜",
            "level": éš¾åº¦ç­‰çº§,
            "difficulty": "éš¾åº¦æè¿°",
            "options": [
                {"label": "A", "value": "A", "text": "é€‰é¡¹å†…å®¹"},
                {"label": "B", "value": "B", "text": "é€‰é¡¹å†…å®¹"},
                {"label": "C", "value": "C", "text": "é€‰é¡¹å†…å®¹"},
                {"label": "D", "value": "D", "text": "é€‰é¡¹å†…å®¹"}
            ]
        }
    }
    """
    try:
        # è·å–è¯·æ±‚ä½“
        body = await request.json()
        
        # éªŒè¯è¯·æ±‚æ•°æ®
        if "question" not in body:
            return JSONResponse(
                status_code=400,
                content={"error": "è¯·æ±‚ä½“ä¸­ç¼ºå°‘questionå­—æ®µ"}
            )
        
        question_data = body["question"]
        
        # éªŒè¯é¢˜ç›®æ•°æ®
        if not explanation_processor.validate_question_data(question_data):
            return JSONResponse(
                status_code=400,
                content={"error": "é¢˜ç›®æ•°æ®æ ¼å¼ä¸æ­£ç¡®"}
            )
        
        # ç”Ÿæˆè§£æ
        result = explanation_processor.generate_explanation(question_data)
        
        return JSONResponse(content=result)
        
    except json.JSONDecodeError:
        return JSONResponse(
            status_code=400,
            content={"error": "è¯·æ±‚ä½“ä¸æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼"}
        )
    except Exception as e:
        return JSONResponse(
            status_code=500,
            content={"error": f"ç”Ÿæˆè§£æå¤±è´¥: {str(e)}"}
        )

@app.post("/api/generate-batch-explanations")
async def generate_batch_explanations(request: Request):
    """
    æ‰¹é‡ç”Ÿæˆå¤šä¸ªé¢˜ç›®çš„ç­”æ¡ˆè§£æ
    
    è¯·æ±‚ä½“æ ¼å¼ï¼š
    {
        "questions": [
            {
                "question_text": "é¢˜ç›®æ–‡æœ¬",
                "question_type": "codeæˆ–text",
                "question_code": "ä»£ç å†…å®¹æˆ–ç©ºå­—ç¬¦ä¸²",
                "correct_answer": "æ­£ç¡®ç­”æ¡ˆæ ‡ç­¾",
                "explanation": "åŸå§‹è§£é‡Šè¯´æ˜",
                "level": éš¾åº¦ç­‰çº§,
                "difficulty": "éš¾åº¦æè¿°",
                "options": [
                    {"label": "A", "value": "A", "text": "é€‰é¡¹å†…å®¹"},
                    {"label": "B", "value": "B", "text": "é€‰é¡¹å†…å®¹"},
                    {"label": "C", "value": "C", "text": "é€‰é¡¹å†…å®¹"},
                    {"label": "D", "value": "D", "text": "é€‰é¡¹å†…å®¹"}
                ]
            }
        ]
    }
    """
    try:
        # è·å–è¯·æ±‚ä½“
        body = await request.json()
        
        # éªŒè¯è¯·æ±‚æ•°æ®
        if "questions" not in body:
            return JSONResponse(
                status_code=400,
                content={"error": "è¯·æ±‚ä½“ä¸­ç¼ºå°‘questionså­—æ®µ"}
            )
        
        questions = body["questions"]
        
        if not isinstance(questions, list):
            return JSONResponse(
                status_code=400,
                content={"error": "questionså­—æ®µå¿…é¡»æ˜¯æ•°ç»„"}
            )
        
        if len(questions) == 0:
            return JSONResponse(
                status_code=400,
                content={"error": "questionsæ•°ç»„ä¸èƒ½ä¸ºç©º"}
            )
        
        # éªŒè¯æ¯ä¸ªé¢˜ç›®æ•°æ®
        for i, question in enumerate(questions):
            if not explanation_processor.validate_question_data(question):
                return JSONResponse(
                    status_code=400,
                    content={"error": f"ç¬¬{i+1}ä¸ªé¢˜ç›®æ•°æ®æ ¼å¼ä¸æ­£ç¡®"}
                )
        
        # æ‰¹é‡ç”Ÿæˆè§£æ
        results = explanation_processor.generate_batch_explanations(questions)
        
        return JSONResponse(content={
            "results": results,
            "total_count": len(results),
            "success_count": len([r for r in results if r["status"] == "success"]),
            "error_count": len([r for r in results if r["status"] == "error"])
        })
        
    except json.JSONDecodeError:
        return JSONResponse(
            status_code=400,
            content={"error": "è¯·æ±‚ä½“ä¸æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼"}
        )
    except Exception as e:
        return JSONResponse(
            status_code=500,
            content={"error": f"æ‰¹é‡ç”Ÿæˆè§£æå¤±è´¥: {str(e)}"}
        )


@app.post("/api/stream-extract")
async def stream_extract_pdf(
    file: UploadFile = File(...),
    expected_questions: str = Form("")
):
    """
    æµå¼å¤„ç†PDFæ–‡ä»¶ï¼Œå®æ—¶è¿”å›é¢˜ç›®ç»“æœ
    ä½¿ç”¨LLMçš„æµå¼è¾“å‡ºï¼Œæ¯å½“ç”Ÿæˆä¸€ä¸ªå®Œæ•´é¢˜ç›®å°±ç«‹å³è¿”å›
    """
    # å¤„ç†expected_questionså‚æ•°
    expected_questions_int = None
    if expected_questions and expected_questions.strip():
        try:
            expected_questions_int = int(expected_questions)
        except ValueError:
            print(f"âš ï¸ é¢„æœŸé¢˜ç›®æ•°è½¬æ¢å¤±è´¥: {expected_questions}")
    
    # å…ˆè¯»å–æ–‡ä»¶å†…å®¹
    content = await file.read()
    
    def generate_stream():
        """ç”Ÿæˆæµå¼å“åº”"""
        file_path = None
        try:
            # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶
            file_path = f"temp_{file.filename}"
            with open(file_path, "wb") as buffer:
                buffer.write(content)
            
            # æå–PDFæ–‡æœ¬
            pdf_text = extract_pdf_text(file_path)
            
            # ä½¿ç”¨LLMæµå¼å¤„ç†å™¨
            for data in llm_stream_processor.process_pdf_text_stream(
                pdf_text,
                expected_questions=expected_questions_int
            ):
                yield f"data: {json.dumps(data, ensure_ascii=False)}\n\n"
            
            # å‘é€ç»“æŸæ ‡è®°
            yield f"data: {json.dumps({'type': 'stream_end', 'message': 'æµå¼å¤„ç†å®Œæˆ'}, ensure_ascii=False)}\n\n"
                
        except Exception as e:
            error_data = {
                "type": "error",
                "message": f"æµå¼å¤„ç†å¤±è´¥: {str(e)}",
                "error": str(e)
            }
            yield f"data: {json.dumps(error_data, ensure_ascii=False)}\n\n"
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if file_path and os.path.exists(file_path):
                try:
                    os.remove(file_path)
                except:
                    pass
    
    return StreamingResponse(
        generate_stream(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "Access-Control-Allow-Origin": "*",
            "Access-Control-Allow-Headers": "*",
        }
    )
