import json
import os
import requests
from typing import Dict, Any, List
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading

class LLMProcessor:
    """
    å¤§æ¨¡å‹å¤„ç†å™¨ï¼Œæ”¯æŒæ™ºèƒ½åˆ†å‰²å’Œå®æ—¶è¿›åº¦æ˜¾ç¤º
    """
    
    def __init__(self, api_key: str = None, max_tokens: int = 8000):
        self.api_key = api_key or os.getenv("DASHSCOPE_API_KEY")
        self.api_url = "https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions"
        self.max_tokens = max_tokens
        self.max_input_length = 3000
    
    def create_split_prompt(self, pdf_text: str) -> str:
        """åˆ›å»ºåˆ†å‰²é¢˜ç›®çš„prompt"""
        return f"""è¯·å°†ä»¥ä¸‹PDFæ–‡æœ¬ä¸­çš„é¢˜ç›®è¿›è¡Œæ™ºèƒ½åˆ†å‰²ï¼Œæ¯ä¸ªåˆ†å‰²ç‰‡æ®µåº”è¯¥åŒ…å«1-3ä¸ªå®Œæ•´çš„é¢˜ç›®ã€‚

è¦æ±‚ï¼š
1. æ¯ä¸ªåˆ†å‰²ç‰‡æ®µåº”è¯¥åŒ…å«å®Œæ•´çš„é¢˜ç›®ï¼ˆåŒ…æ‹¬é¢˜ç›®ã€é€‰é¡¹ã€ç­”æ¡ˆç­‰ï¼‰
2. åˆ†å‰²ç‰‡æ®µé•¿åº¦æ§åˆ¶åœ¨åˆç†èŒƒå›´å†…ï¼Œä¾¿äºåç»­å¤„ç†
3. è¿”å›JSONæ ¼å¼çš„åˆ†å‰²ç»“æœ

PDFæ–‡æœ¬ï¼š
{pdf_text}

è¯·è¿”å›ä»¥ä¸‹JSONæ ¼å¼ï¼š
{{
    "segments": [
        {{
            "id": 1,
            "content": "ç¬¬ä¸€ä¸ªåˆ†å‰²ç‰‡æ®µçš„å†…å®¹",
            "estimated_questions": 2
        }}
    ]
}}"""
    
    def create_question_prompt(self, segment_content: str, expected_questions: int = None) -> str:
        """åˆ›å»ºæå–é¢˜ç›®çš„prompt"""
        calibration_text = ""
        if expected_questions is not None:
            calibration_text = f"\n6. è¯·ä»”ç»†æ£€æŸ¥æ–‡æœ¬ï¼Œç¡®ä¿æå–æ‰€æœ‰é¢˜ç›®ã€‚é¢„æœŸé¢˜ç›®æ•°é‡çº¦ä¸º {expected_questions} ä¸ªï¼Œå¦‚æœå‘ç°é¢˜ç›®æ•°é‡æ˜æ˜¾å°‘äºé¢„æœŸï¼Œè¯·é‡æ–°ä»”ç»†æ£€æŸ¥æ–‡æœ¬å†…å®¹ã€‚"
        
        return f"""è¯·å°†ä»¥ä¸‹æ–‡æœ¬ä¸­çš„é¢˜ç›®è½¬æ¢ä¸ºæ ‡å‡†JSONæ ¼å¼ã€‚

è¦æ±‚ï¼š
1. åˆ†question_typeä¸¤ç±»é¢˜ç›®ï¼šcodeå’Œtext
2. å¦‚æœé¢˜ç›®æœ‰ä»£ç ï¼Œåˆ™æ˜¯codeç±»å‹ï¼Œåä¹‹text
3. å¦‚æœæ˜¯codeç±»å‹ï¼Œåˆ™æœ‰question_codeå­—æ®µï¼Œå¦‚æœæ˜¯textç±»å‹ï¼Œåˆ™question_codeæ˜¯ç©ºå­—ç¬¦ä¸²
4. æ¯ä¸ªé¢˜ç›®åŒ…å«ï¼šquestion_text, question_type, question_code, correct_answer, explanation, level, difficulty, options
5. levelè¡¨ç¤ºéš¾åº¦ç­‰çº§ï¼ˆ1-5ï¼‰ï¼Œdifficultyè¡¨ç¤ºéš¾åº¦æè¿°ï¼ˆeasy/medium/hardï¼‰{calibration_text}

æ–‡æœ¬å†…å®¹ï¼š
{segment_content}

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºï¼š
[
  {{
    "question_text": "é¢˜ç›®æ–‡æœ¬",
    "question_type": "codeæˆ–text",
    "question_code": "ä»£ç å†…å®¹æˆ–ç©ºå­—ç¬¦ä¸²",
    "correct_answer": "æ­£ç¡®ç­”æ¡ˆæ ‡ç­¾",
    "explanation": "è§£é‡Šè¯´æ˜",
    "level": éš¾åº¦ç­‰çº§,
    "difficulty": "éš¾åº¦æè¿°",
    "options": [
      {{"label": "A", "value": "A", "text": "é€‰é¡¹å†…å®¹"}},
      {{"label": "B", "value": "B", "text": "é€‰é¡¹å†…å®¹"}},
      {{"label": "C", "value": "C", "text": "é€‰é¡¹å†…å®¹"}},
      {{"label": "D", "value": "D", "text": "é€‰é¡¹å†…å®¹"}}
    ]
  }}
]"""
    
    def call_api(self, prompt: str) -> str:
        """è°ƒç”¨DashScope API"""
        try:
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {self.api_key}"
            }
            
            data = {
                "model": "qwen-plus",
                "messages": [
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é¢˜ç›®è§£æåŠ©æ‰‹ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                "temperature": 0.3,
                "max_tokens": self.max_tokens
            }
            
            response = requests.post(self.api_url, headers=headers, json=data, timeout=120)
            response.raise_for_status()
            
            result = response.json()
            return result["choices"][0]["message"]["content"]
            
        except Exception as e:
            raise Exception(f"è°ƒç”¨DashScope APIå¤±è´¥: {str(e)}")
    
    def parse_json_response(self, response: str) -> List[Dict[str, Any]]:
        """è§£æJSONå“åº”"""
        try:
            if response.strip().startswith('[') and response.strip().endswith(']'):
                return json.loads(response)
            elif response.strip().startswith('{') and response.strip().endswith('}'):
                return json.loads(response)
            
            # æå–JSONéƒ¨åˆ†
            start_idx = response.find('[')
            end_idx = response.rfind(']') + 1
            
            if start_idx != -1 and end_idx != 0:
                json_str = response[start_idx:end_idx]
                return json.loads(json_str)
            else:
                start_idx = response.find('{')
                end_idx = response.rfind('}') + 1
                if start_idx != -1 and end_idx != 0:
                    json_str = response[start_idx:end_idx]
                    return json.loads(json_str)
                else:
                    raise ValueError("æ— æ³•æ‰¾åˆ°æœ‰æ•ˆçš„JSONæ ¼å¼")
                
        except json.JSONDecodeError as e:
            raise ValueError(f"JSONè§£æå¤±è´¥: {str(e)}")
        except Exception as e:
            raise ValueError(f"è§£æå“åº”å¤±è´¥: {str(e)}")
    
    def split_text_intelligently(self, pdf_text: str) -> List[Dict[str, Any]]:
        """å¿«é€Ÿå¯å‘å¼åˆ†å‰²æ–‡æœ¬"""
        try:
            if len(pdf_text) <= self.max_input_length:
                return [{"id": 1, "content": pdf_text, "estimated_questions": 1}]
            
            print(f"ğŸ“ æ–‡æœ¬è¿‡é•¿ï¼Œä½¿ç”¨å¿«é€Ÿå¯å‘å¼åˆ†å‰²...")
            return self.fast_heuristic_split(pdf_text)
                
        except Exception as e:
            print(f"âš ï¸ å¿«é€Ÿåˆ†å‰²å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ: {str(e)}")
            return self.fallback_split(pdf_text)
    
    def fast_heuristic_split(self, text: str) -> List[Dict[str, Any]]:
        """å¿«é€Ÿå¯å‘å¼åˆ†å‰²"""
        import re
        
        # åˆ†å‰²å‚æ•°
        MIN_SEGMENT_SIZE = 800
        MAX_SEGMENT_SIZE = 3000
        TARGET_SEGMENT_SIZE = 2000
        
        segments = []
        current_segment = ""
        segment_id = 1
        
        # æŒ‰æ®µè½åˆ†å‰²
        paragraphs = text.split('\n\n')
        
        for paragraph in paragraphs:
            paragraph = paragraph.strip()
            if not paragraph:
                continue
                
            # å¦‚æœå½“å‰æ®µè½åŠ ä¸Šæ–°æ®µè½è¶…è¿‡ç›®æ ‡å¤§å°ï¼Œä¸”å½“å‰æ®µè½ä¸ä¸ºç©º
            if current_segment and len(current_segment + "\n\n" + paragraph) > TARGET_SEGMENT_SIZE:
                # ä¿å­˜å½“å‰ç‰‡æ®µ
                if len(current_segment) >= MIN_SEGMENT_SIZE:
                    segments.append({
                        "id": segment_id,
                        "content": current_segment.strip(),
                        "estimated_questions": self._estimate_questions(current_segment)
                    })
                    segment_id += 1
                    current_segment = paragraph
                else:
                    # å½“å‰ç‰‡æ®µå¤ªå°ï¼Œç»§ç»­æ·»åŠ 
                    current_segment += "\n\n" + paragraph
            else:
                # æ·»åŠ åˆ°å½“å‰ç‰‡æ®µ
                if current_segment:
                    current_segment += "\n\n" + paragraph
                else:
                    current_segment = paragraph
        
        # å¤„ç†æœ€åä¸€ä¸ªç‰‡æ®µ
        if current_segment and len(current_segment) >= MIN_SEGMENT_SIZE:
            segments.append({
                "id": segment_id,
                "content": current_segment.strip(),
                "estimated_questions": self._estimate_questions(current_segment)
            })
        
        # å¦‚æœåˆ†å‰²åç‰‡æ®µå¤ªå°‘ï¼Œå°è¯•æ›´ç»†ç²’åº¦çš„åˆ†å‰²
        if len(segments) < 2 and len(text) > MAX_SEGMENT_SIZE:
            return self._fine_grained_split(text)
        
        return segments
    
    def _estimate_questions(self, text: str) -> int:
        """ä¼°ç®—ç‰‡æ®µä¸­çš„é¢˜ç›®æ•°é‡"""
        import re
        
        # é¢˜ç›®ç¼–å·æ¨¡å¼
        patterns = [
            r'\d+\.',  # 1. 2. 3.
            r'ç¬¬\d+é¢˜',  # ç¬¬1é¢˜ ç¬¬2é¢˜
            r'é¢˜ç›®\d+',  # é¢˜ç›®1 é¢˜ç›®2
            r'Q\d+',    # Q1 Q2
            r'\(\d+\)',  # (1) (2)
            r'[A-D]\.',  # A. B. C. D.
        ]
        
        question_count = 0
        for pattern in patterns:
            matches = re.findall(pattern, text)
            question_count += len(matches)
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°é¢˜ç›®ç¼–å·ï¼Œæ ¹æ®æ–‡æœ¬é•¿åº¦ä¼°ç®—
        if question_count == 0:
            question_count = max(1, len(text) // 1000)
        
        return question_count
    
    def _fine_grained_split(self, text: str) -> List[Dict[str, Any]]:
        """ç»†ç²’åº¦åˆ†å‰²ï¼Œç”¨äºå¤„ç†å¤§ç‰‡æ®µ"""
        import re
        
        segments = []
        segment_id = 1
        
        # æŒ‰å¥å­åˆ†å‰²
        sentences = re.split(r'[ã€‚ï¼ï¼Ÿ\n]+', text)
        current_segment = ""
        
        for sentence in sentences:
            sentence = sentence.strip()
            if not sentence:
                continue
                
            if len(current_segment + sentence) > 2000:
                if current_segment:
                    segments.append({
                        "id": segment_id,
                        "content": current_segment.strip(),
                        "estimated_questions": self._estimate_questions(current_segment)
                    })
                    segment_id += 1
                    current_segment = sentence
                else:
                    current_segment = sentence
            else:
                current_segment += sentence
        
        # å¤„ç†æœ€åä¸€ä¸ªç‰‡æ®µ
        if current_segment:
            segments.append({
                "id": segment_id,
                "content": current_segment.strip(),
                "estimated_questions": self._estimate_questions(current_segment)
            })
        
        return segments
    
    def fallback_split(self, text: str) -> List[Dict[str, Any]]:
        """å¤‡ç”¨åˆ†å‰²æ–¹æ¡ˆ"""
        paragraphs = text.split('\n\n')
        segments = []
        
        for i, para in enumerate(paragraphs):
            if len(para.strip()) > 100:
                segments.append({
                    "id": i + 1,
                    "content": para.strip(),
                    "estimated_questions": 1
                })
        
        return segments
    

    
    def process_segment(self, segment: Dict[str, Any], segment_index: int, expected_questions: int = None) -> Dict[str, Any]:
        """å¤„ç†å•ä¸ªç‰‡æ®µ"""
        try:
            print(f"ğŸ”„ å¼€å§‹å¤„ç†ç¬¬ {segment_index + 1} ä¸ªç‰‡æ®µ...")
            prompt = self.create_question_prompt(segment['content'], expected_questions)
            response = self.call_api(prompt)
            questions = self.parse_json_response(response)
            
            if isinstance(questions, list):
                print(f"âœ… ç¬¬ {segment_index + 1} ä¸ªç‰‡æ®µå®Œæˆï¼Œæå–åˆ° {len(questions)} ä¸ªé¢˜ç›®")
                return {
                    "segment_index": segment_index,
                    "segment_id": segment.get("id", segment_index + 1),
                    "questions": questions,
                    "success": True
                }
            else:
                print(f"âš ï¸ ç¬¬ {segment_index + 1} ä¸ªç‰‡æ®µè§£æå¤±è´¥")
                return {
                    "segment_index": segment_index,
                    "segment_id": segment.get("id", segment_index + 1),
                    "questions": [],
                    "success": False
                }
                
        except Exception as e:
            print(f"âŒ ç¬¬ {segment_index + 1} ä¸ªç‰‡æ®µå¤„ç†å¤±è´¥: {str(e)}")
            return {
                "segment_index": segment_index,
                "segment_id": segment.get("id", segment_index + 1),
                "questions": [],
                "success": False,
                "error": str(e)
            }

    def process_pdf_text_with_progress(self, pdf_text: str, max_workers: int = 3, progress_id: str = None, expected_questions: int = None) -> List[Dict[str, Any]]:
        """å¤„ç†PDFæ–‡æœ¬ï¼ˆå¸¦è¿›åº¦ç‰ˆæœ¬ï¼‰"""
        try:
            segments = self.split_text_intelligently(pdf_text)
            self.last_segments = segments  # ä¿å­˜åˆ†å‰²ç»“æœ
            
            # å‘é€åˆ†å‰²å®Œæˆæ¶ˆæ¯
            if progress_id:
                from main import progress_storage
                progress_storage[progress_id] = {
                    "type": "split_complete",
                    "message": f"åˆ†å‰²å®Œæˆï¼Œå…± {len(segments)} ä¸ªç‰‡æ®µ",
                    "segment_count": len(segments),
                    "parallel_workers": max_workers
                }
            
            print(f"ğŸ“Š åˆ†å‰²ä¸º {len(segments)} ä¸ªç‰‡æ®µï¼Œä½¿ç”¨ {max_workers} ä¸ªå¹¶è¡Œçº¿ç¨‹")
            
            # åˆå§‹åŒ–ç»“æœå­˜å‚¨ï¼ŒæŒ‰ç‰‡æ®µç´¢å¼•æ’åº
            segment_results = [None] * len(segments)
            completed_count = 0
            
            # ä½¿ç”¨çº¿ç¨‹æ± è¿›è¡Œå¹¶è¡Œå¤„ç†
            with ThreadPoolExecutor(max_workers=max_workers) as executor:
                # æäº¤æ‰€æœ‰ä»»åŠ¡
                future_to_segment = {
                    executor.submit(self.process_segment, segment, i, expected_questions): (i, segment)
                    for i, segment in enumerate(segments)
                }
                
                # æ”¶é›†ç»“æœ
                for future in as_completed(future_to_segment):
                    segment_index, segment = future_to_segment[future]
                    try:
                        result = future.result()
                        # æŒ‰ç‰‡æ®µç´¢å¼•å­˜å‚¨ç»“æœï¼Œä¿æŒé¡ºåº
                        segment_results[segment_index] = result
                        completed_count += 1
                        
                        # å‘é€è¿›åº¦æ›´æ–°
                        if progress_id:
                            from main import progress_storage
                            progress_storage[progress_id] = {
                                "type": "progress",
                                "message": f"å¤„ç†ç¬¬ {completed_count}/{len(segments)} ä¸ªç‰‡æ®µ",
                                "completed": completed_count,
                                "total": len(segments),
                                "questions_found": len(result.get("questions", [])),
                                "total_questions": sum(len(r.get("questions", [])) for r in segment_results if r is not None)
                            }
                        
                        print(f"ğŸ“ˆ è¿›åº¦: {completed_count}/{len(segments)} ä¸ªç‰‡æ®µå·²å®Œæˆ")
                    except Exception as e:
                        print(f"âŒ ç‰‡æ®µ {segment_index + 1} å¤„ç†å¼‚å¸¸: {str(e)}")
                        segment_results[segment_index] = {
                            "segment_index": segment_index,
                            "segment_id": segment.get("id", segment_index + 1),
                            "questions": [],
                            "success": False,
                            "error": str(e)
                        }
                        completed_count += 1
            
            # æŒ‰åŸå§‹é¡ºåºåˆå¹¶æ‰€æœ‰é¢˜ç›®
            all_questions = []
            for result in segment_results:
                if result and result.get("success"):
                    all_questions.extend(result["questions"])
            
            print(f"ğŸ‰ æ‰€æœ‰ç‰‡æ®µå¤„ç†å®Œæˆï¼æ€»å…±æå–åˆ° {len(all_questions)} ä¸ªé¢˜ç›®")
            return all_questions
            
        except Exception as e:
            raise Exception(f"å¤„ç†PDFæ–‡æœ¬å¤±è´¥: {str(e)}")
    
    def process_pdf_text(self, pdf_text: str, max_workers: int = 3, expected_questions: int = None) -> List[Dict[str, Any]]:
        """å¤„ç†PDFæ–‡æœ¬ï¼ˆå¹¶è¡Œç‰ˆæœ¬ï¼‰"""
        try:
            segments = self.split_text_intelligently(pdf_text)
            self.last_segments = segments  # ä¿å­˜åˆ†å‰²ç»“æœ
            print(f"ğŸ“Š åˆ†å‰²ä¸º {len(segments)} ä¸ªç‰‡æ®µï¼Œä½¿ç”¨ {max_workers} ä¸ªå¹¶è¡Œçº¿ç¨‹")
            
            # åˆå§‹åŒ–ç»“æœå­˜å‚¨ï¼ŒæŒ‰ç‰‡æ®µç´¢å¼•æ’åº
            segment_results = [None] * len(segments)
            completed_count = 0
            
            # ä½¿ç”¨çº¿ç¨‹æ± è¿›è¡Œå¹¶è¡Œå¤„ç†
            with ThreadPoolExecutor(max_workers=max_workers) as executor:
                # æäº¤æ‰€æœ‰ä»»åŠ¡
                future_to_segment = {
                    executor.submit(self.process_segment, segment, i, expected_questions): (i, segment)
                    for i, segment in enumerate(segments)
                }
                
                # æ”¶é›†ç»“æœ
                for future in as_completed(future_to_segment):
                    segment_index, segment = future_to_segment[future]
                    try:
                        result = future.result()
                        # æŒ‰ç‰‡æ®µç´¢å¼•å­˜å‚¨ç»“æœï¼Œä¿æŒé¡ºåº
                        segment_results[segment_index] = result
                        completed_count += 1
                        print(f"ğŸ“ˆ è¿›åº¦: {completed_count}/{len(segments)} ä¸ªç‰‡æ®µå·²å®Œæˆ")
                    except Exception as e:
                        print(f"âŒ ç‰‡æ®µ {segment_index + 1} å¤„ç†å¼‚å¸¸: {str(e)}")
                        segment_results[segment_index] = {
                            "segment_index": segment_index,
                            "segment_id": segment.get("id", segment_index + 1),
                            "questions": [],
                            "success": False,
                            "error": str(e)
                        }
                        completed_count += 1
            
            # æŒ‰åŸå§‹é¡ºåºåˆå¹¶æ‰€æœ‰é¢˜ç›®
            all_questions = []
            for result in segment_results:
                if result and result.get("success"):
                    all_questions.extend(result["questions"])
            
            print(f"ğŸ‰ æ‰€æœ‰ç‰‡æ®µå¤„ç†å®Œæˆï¼æ€»å…±æå–åˆ° {len(all_questions)} ä¸ªé¢˜ç›®")
            return all_questions
            
        except Exception as e:
            raise Exception(f"å¤„ç†PDFæ–‡æœ¬å¤±è´¥: {str(e)}")
    
    def get_last_segments(self) -> List[Dict[str, Any]]:
        """è·å–æœ€åçš„åˆ†å‰²ç»“æœ"""
        return getattr(self, 'last_segments', []) 